###########################
# Credentials

# https://ai.google.dev/gemini-api/docs/api-key
#GEMINI_API_KEY=

# https://app.tavily.com/home
#TAVILY_API_KEY=

# This is passed to the LiteLLM server
LITELLM_MASTER_KEY=sk-1234

# https://console.anthropic.com/settings/keys
#ANTHROPIC_API_KEY=

# OpenRouter has free models: https://openrouter.ai/models?max_price=0
# https://openrouter.ai/settings/keys
#OPENROUTER_API_KEY=

# https://app.linkup.so/home
#LINKUP_API_KEY=

# https://jina.ai/api-dashboard
#JINA_API_KEY=

# Stack Exchange Key, optional
#STACKOVERFLOW_API_KEY=

# Zotero Library ID, optional
# https://www.zotero.org/settings/keys
#ZOTERO_LIBRARY_ID=
#ZOTERO_API_KEY=

# Notion API Key, optional
#NOTION_API_KEY=

# Github personal access token (useful for private repos and rate limits)
#GITHUB_API_KEY=

###########################
## LM Studio

# https://docs.litellm.ai/docs/providers/lm_studio#api-key
#LM_STUDIO_API_BASE=http://host.docker.internal:1234
#LM_STUDIO_API_KEY=

###########################
## Ollama

OLLAMA_BASE_URL=http://host.docker.internal:11434

###########################
## Open WebUI

# https://docs.openwebui.com/getting-started/env-configuration#openai
# This is disabled so that only Letta is shown, enable this to get access to more models
ENABLE_OPENAI_API=false

# https://docs.openwebui.com/getting-started/env-configuration#ollama
ENABLE_OLLAMA_API=false

# https://docs.openwebui.com/getting-started/env-configuration#tasks
ENABLE_TITLE_GENERATION=false
ENABLE_TAGS_GENERATION=false

# We want the absolute cheapest models for tasks https://www.llm-prices.com
TASK_MODEL_EXTERNAL=gemini/gemini-1.5-flash-8b
TASK_MODEL=gemini/gemini-1.5-flash-8b

# https://docs.openwebui.com/getting-started/env-configuration#rag_embedding_engine
RAG_EMBEDDING_ENGINE=openai
RAG_EMBEDDING_MODEL=gemini/gemini-embedding-exp-03-07

# Disable Open WebUI web search as we want it to go through Letta
ENABLE_WEB_SEARCH=false
WEB_SEARCH_ENGINE=tavily

# Disable audio options
AUDIO_STT_ENGINE=

###########################
## Hayhooks 

# Set this to false to disable SearXNG
HAYHOOKS_SEARCH_SEARXNG_ENABLED=true

# The logging level for Hayhooks
HAYHOOKS_LOG_LEVEL=WARNING

# The base hayhooks URL to pass to the agent tools env
HAYHOOKS_BASE_URL=http://hayhooks:1416

# The model to use in the 'search' tool.
HAYHOOKS_SEARCH_MODEL=gemini/gemini-2.0-flash

# The model to use in the 'excerpt' tool.
HAYHOOKS_EXCERPT_MODEL=gemini/gemini-2.0-flash

# The model to use when summarizing emails.
HAYHOOKS_SEARCH_EMAIL_MODEL=gemini/gemini-2.0-flash

# Uncomment these models to use Claude Haiku
#HAYHOOKS_EXCERPT_MODEL=anthropic/claude-3-5-haiku-latest
#HAYHOOKS_SEARCH_MODEL=anthropic/claude-3-5-haiku-latest
#HAYHOOKS_SEARCH_EMAIL_MODEL=anthropic/claude-3-5-haiku-latest

###########################
## Letta
#
# You can see an updated list of models at https://docs.letta.com/leaderboard
#
# gemini-2.5-flash is most cost effective right now.
#
# google_ai/gemini-2.5-pro-preview-05-06 is probably the single best model.
#
#if you prefer using Anthropic, be warned that it has *very* low rate limits
#- LETTA_CHAT_MODEL=anthropic/claude-sonnet-4-20250514
#
# If you don't have a google api key at all, you can always use letta/letta-free
#- LETTA_CHAT_MODEL=letta/letta-free

# The model to the search agent to use to chat. 
LETTA_CHAT_MODEL=google_ai/gemini-2.5-flash-preview-05-20

# The embedding model used to save archival memory.
LETTA_EMBEDDING_MODEL=letta/letta-free

# Uncomment this to see the arguments used in tool calls
#LETTA_CHAT_DEBUG_TOOL_STATEMENTS=true
