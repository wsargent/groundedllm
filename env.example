# https://ai.google.dev/gemini-api/docs/api-key
GEMINI_API_KEY=

# https://app.tavily.com/home
TAVILY_API_KEY=

# This is passed to the LiteLLM server
LITELLM_MASTER_KEY=sk-1234

# https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=

# https://github.com/settings/personal-access-tokens
GITHUB_PERSONAL_ACCESS_TOKEN=

RAG_EMBEDDING_MODEL=text-embedding-005

# https://developers.googleblog.com/en/gemma-3-quantized-aware-trained-state-of-the-art-ai-to-consumer-gpus/?linkId=14034718
# ollama run gemma3:12b-it-qat
# ollama run gemma3:24b-it-qat
# https://github.com/ollama/ollama/tree/main/docs
OLLAMA_BASE_URL=http://host.docker.internal:11434/

SEARCH_MODEL=gemini-2.0-flash

EXTRACT_MODEL=gemini-2.0-flash

#if you prefer using Anthropic, be warned that it has *very* low rate limits
#- CHAT_MODEL=anthropic/claude-3-7-sonnet-20250219
#
# If you don't have a google api key at all, you can always use letta/letta-free
#- CHAT_MODEL=letta/letta-free
#
# Priced competitively, this gives developers access to increased rate limits to use with 2.5 Pro. 
# The experimental version of Gemini 2.5 Pro remains available for free with lower rate limits. 
#   -- https://blog.google/products/gemini/gemini-preview-model-billing-update/
#
# Note: 'gemini-2.5-pro-preview-03-25' is a billed model,
# you can continue to use 'gemini-2.5-pro-exp-03-25' on the free tier.
#   -- https://ai.google.dev/gemini-api/docs/thinking
#

# This embedding model is likewise free (for now), you can also use letta/letta-free
#EMBEDDING_MODEL=letta/letta-free      
EMBEDDING_MODEL=google_ai/gemini-embedding-exp-03-07
