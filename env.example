###########################
# Credentials

# https://ai.google.dev/gemini-api/docs/api-key
GEMINI_API_KEY=

# https://app.tavily.com/home
TAVILY_API_KEY=

# This is passed to the LiteLLM server
LITELLM_MASTER_KEY=sk-1234

# https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=

# OpenRouter has free models: https://openrouter.ai/models?max_price=0
# https://openrouter.ai/settings/keys
OPENROUTER_API_KEY=

# https://app.linkup.so/home
LINKUP_API_KEY=

###########################
## LM Studio

# https://docs.litellm.ai/docs/providers/lm_studio#api-key
LM_STUDIO_API_BASE=http://host.docker.internal:1234
LM_STUDIO_API_KEY=

###########################
## Ollama

OLLAMA_BASE_URL=http://host.docker.internal:11434

###########################
## Open WebUI

# https://docs.openwebui.com/getting-started/env-configuration#openai
# This is disabled so that only Letta is shown, enable this to get access to more models
ENABLE_OPENAI_API=false

# https://docs.openwebui.com/getting-started/env-configuration#ollama
ENABLE_OLLAMA_API=false

# https://docs.openwebui.com/getting-started/env-configuration#tasks
ENABLE_TITLE_GENERATION=false
ENABLE_TAGS_GENERATION=false
TASK_MODEL_EXTERNAL=gemini/gemini-2.0-flash-lite
TASK_MODEL=gemini/gemini-2.0-flash-lite

# https://docs.openwebui.com/getting-started/env-configuration#rag_embedding_engine
RAG_EMBEDDING_ENGINE=openai
RAG_EMBEDDING_MODEL=gemini/gemini-embedding-exp-03-07

# Disable Open WebUI web search as we want it to go through Letta
ENABLE_WEB_SEARCH=false
WEB_SEARCH_ENGINE=tavily

# Disable audio options
AUDIO_STT_ENGINE=

###########################
## Hayhooks 

# The model to use in the 'search' tool.
HAYHOOKS_SEARCH_MODEL=gemini/gemini-2.0-flash

# Set this to false to disable SearXNG
HAYHOOKS_SEARCH_SEARXNG_ENABLED=true

# The model to use in the 'excerpt' tool.
HAYHOOKS_EXCERPT_MODEL=gemini/gemini-2.0-flash

# The logging level for Hayhooks
HAYHOOKS_LOG_LEVEL=WARNING

###########################
## Letta
#
#if you prefer using Anthropic, be warned that it has *very* low rate limits
#- LETTA_CHAT_MODEL=anthropic/claude-3-7-sonnet-20250219
#
# If you don't have a google api key at all, you can always use letta/letta-free
#- LETTA_CHAT_MODEL=letta/letta-free
#
# Priced competitively, this gives developers access to increased rate limits to use with 2.5 Pro. 
# The experimental version of Gemini 2.5 Pro remains available for free with lower rate limits. 
#   -- https://blog.google/products/gemini/gemini-preview-model-billing-update/
#
# Note: 'gemini-2.5-pro-preview-03-25' is a billed model,
# you can continue to use 'gemini-2.5-pro-exp-03-25' on the free tier.
#   -- https://ai.google.dev/gemini-api/docs/thinking
#

# The model to the search agent to use to chat.
#LETTA_CHAT_MODEL=google_ai/gemini-2.5-pro-exp-03-25
LETTA_CHAT_MODEL=google_ai/gemini-2.5-pro-preview-03-25

# The embedding model used to save archival memory.
LETTA_EMBEDDING_MODEL=letta/letta-free
