model_list:

  ######################################
  # Chat Models
  # https://docs.litellm.ai/docs/providers/

  - model_name: "gemini/gemini-2.5-pro-exp-03-25"
    litellm_params:
      model: "gemini/gemini-2.5-pro-exp-03-25"
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]
    model_info:
      max_input_tokens: 1048576
      max_output_tokens: 8192

  - model_name: "gemini/gemini-2.0-flash"
    litellm_params:
      model: "gemini/gemini-2.0-flash"
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]

  - model_name: "gemini/gemini-2.0-flash-lite"
    litellm_params:
      model: "gemini/gemini-2.0-flash-lite"
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]

  # Include all Ollama models to Open WebUI (Letta does not see wildcards)
  - model_name: "ollama_chat/*"
    litellm_params:
      model: "ollama_chat/*"
      api_base: "os.environ/OLLAMA_BASE_URL"
      tags: ["ollama"]

  # Set up mistral-small as a fallback to gemini-2.5-pro
  # Very few openrouter models have free + tools, mistral-small is one of them 
  - model_name: "openrouter/mistralai/mistral-small-3.1-24b-instruct:free"
    litellm_params:
      model: "openrouter/mistralai/mistral-small-3.1-24b-instruct:free"
      api_key: "os.environ/OPENROUTER_API_KEY"
    model_info:
      supports_function_calling: true

  # - model_name: claude-3-7-sonnet
  #   litellm_params:
  #     model: anthropic/claude-3-7-sonnet-20250219
  #     api_key: "os.environ/ANTHROPIC_API_KEY"
  #     tags: ["anthropic"]
  #     extra_headers: {"anthropic-beta": "token-efficient-tools-2025-02-19"}

  ######################################
  # Embedding Models

  - model_name: "gemini/text-embedding-004"
    litellm_params:
      model: "gemini/text-embedding-004"
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]

  - model_name: "gemini/text-embedding-005"
    litellm_params:
      model: "gemini/text-embedding-005"
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]

  # https://ai.google.dev/gemini-api/docs/embeddings
  - model_name: "gemini/gemini-embedding-exp-03-07"
    litellm_params:
      model: "gemini/gemini-embedding-exp-03-07"
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]

litellm_settings:
  request_timeout: 600    # raise Timeout error if call takes longer than 600 seconds.
  drop_params: true  # Useful when we have ollama models that don't take full params