model_list:

  ######################################
  # Chat Models

  # A full list of providers is here: https://docs.litellm.ai/docs/providers/
  - model_name: gemini-2.5-pro
    litellm_params:
      model: gemini/gemini-2.5-pro-exp-03-25
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]
    model_info:
      max_input_tokens: 1048576
      max_output_tokens: 8192

  - model_name: gemini-2.0-flash
    litellm_params:
      model: gemini/gemini-2.0-flash
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]

  - model_name: gemini-2.0-flash-lite
    litellm_params:
      model: gemini/gemini-2.0-flash-lite
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]

  - model_name: "ollama_chat/qwen3:14b"
    litellm_params:
      model: "ollama_chat/qwen3:14b"
      keep_alive: "8m" # Optional: Overrides default keep_alive, use -1 for Forever
      api_base: "os.environ/OLLAMA_BASE_URL"
      tags: ["qwen3"]
      
  # If you are on Mac, you'll want to use LM Studio with MLX
  # https://lmstudio.ai/docs/app/api
  # https://docs.litellm.ai/docs/providers/lm_studio
  # https://huggingface.co/collections/mlx-community/qwen3-680ff3bcb446bdba2c45c7c4
  - model_name: "lm_studio/qwen3-8b-mlx@4bit"
    litellm_params:
      model: "lm_studio/qwen3-8b-mlx@4bit"
      api_base: "os.environ/LM_STUDIO_API_BASE"
      api_key: "os.environ/LM_STUDIO_API_KEY"
      tags: ["qwen3"]

  # - model_name: claude-3-7-sonnet
  #   litellm_params:
  #     model: anthropic/claude-3-7-sonnet-20250219
  #     api_key: "os.environ/ANTHROPIC_API_KEY"
  #     tags: ["anthropic"]
  #     extra_headers: {"anthropic-beta": "token-efficient-tools-2025-02-19"}

  ######################################
  # Embedding Models

  - model_name: text-embedding-004
    litellm_params:
      model: gemini/text-embedding-004
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]

  - model_name: text-embedding-005
    litellm_params:
      model: gemini/text-embedding-005
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]

  # https://ai.google.dev/gemini-api/docs/embeddings
  - model_name: gemini-embedding-exp-03-07
    litellm_params:
      model: gemini/gemini-embedding-exp-03-07
      api_key: "os.environ/GEMINI_API_KEY"
      tags: ["gemini"]

litellm_settings:
  request_timeout: 600    # raise Timeout error if call takes longer than 600 seconds.
  drop_params: true       # not all models support all the parameters