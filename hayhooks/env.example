# This is useful when you're running Hayhooks outside of a docker container for debugging
# https://docs.haystack.deepset.ai/docs/hayhooks#environment-variables

# LiteLLM can be started from docker
OPENAI_API_BASE="http://localhost:4000"
OPENAI_API_KEY=sk-1234

LETTA_BASE_URL=http;//localhost:8283
OPENWEBUI_BASE_URL=http://localhost:3000

# Set with your tavily key
TAVILY_API_KEY=<your tavily key>

LINKUP_API_KEY=<your linkup key>

# Use this for long context
HAYHOOKS_SEARCH_MODEL=gemini/gemini-2.0-flash
HAYHOOKS_EXCERPT_MODEL=gemini/gemini-2.0-flash

# Useful defaults (I tend to use direct command line though)
#HAYHOOKS_DISABLE_SSL=true
#HAYHOOKS_PIPELINES_DIR=./pipelines
#HAYHOOKS_ADDITIONAL_PYTHONPATH=.
#HAYHOOKS_SHOW_TRACEBACKS=true